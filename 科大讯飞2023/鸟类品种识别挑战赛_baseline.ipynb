{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d01073-09a8-4c68-b93b-aef463738bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d2263d-916c-431e-aca7-3e5bcd867f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = glob.glob('./train_data/training_set/*/*')\n",
    "np.random.shuffle(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d68b4a-10c8-49f3-a71e-e52c86fe2bae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20368\n"
     ]
    }
   ],
   "source": [
    "n = len(train_path)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741e8f00-8f17-4e53-8d7d-5db166c794ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4073\n"
     ]
    }
   ],
   "source": [
    "n_test = int(0.2 * n)\n",
    "print(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07dd3058-80a6-451d-af4d-2900845f4540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['Asian Green Bee-Eater', 'Brown-Headed Barbet', 'Cattle Egret',\n",
    "       'Common Kingfisher', 'Common Myna', 'Common Rosefinch',\n",
    "       'Common Tailorbird', 'Coppersmith Barbet', 'Forest Wagtail',\n",
    "       'Gray Wagtail', 'Hoopoe', 'House Crow', 'Indian Grey Hornbill',\n",
    "       'Indian Peacock', 'Indian Pitta', 'Indian Roller',\n",
    "       'Jungle Babbler', 'Northern Lapwing', 'Red-Wattled Lapwing',\n",
    "       'Ruddy Shelduck', 'Rufous Treepie', 'Sarus Crane', 'White Wagtail',\n",
    "       'White-Breasted Kingfisher', 'White-Breasted Waterhen']\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584f2188-cf45-4d72-abee-4dae0d362926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        for idx, label in enumerate(class_names):\n",
    "            if label in self.img_path[index]:\n",
    "                label = idx\n",
    "                break\n",
    "        return img, torch.from_numpy(np.array(label).astype(int))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473a6765-dd3d-4f48-8d34-ab4c32c013b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XunFeiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet, self).__init__()\n",
    "        model = models.resnet18(True)\n",
    "        num_features=model.fc.in_features\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(num_features, len(class_names))\n",
    "        self.resnet = model\n",
    "    \n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47539bef-14a7-4881-85e9-0882ff295e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Train loss', loss.item())\n",
    "            \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    return train_loss/len(train_loader)\n",
    "            \n",
    "def validate(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    val_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            val_acc += (output.argmax(1) == target).sum().item()\n",
    "            \n",
    "    return val_acc / len(val_loader.dataset)\n",
    "\n",
    "def predict(test_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            test_pred.append(output.data.cpu().numpy())\n",
    "            \n",
    "    return np.vstack(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c14b410f-de94-4f52-be5b-1377c34bda4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[:-n_test],\n",
    "    transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ])), batch_size=30, shuffle=True, num_workers=4, pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(train_path[-n_test:],\n",
    "    transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ])), batch_size=15, shuffle=False, num_workers=1, pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f7ee8cb-cfc0-4eb8-96ea-7302144ae7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.8/lib/python3.8/site-packages/torchvision-0.15.0a0+c206a47-py3.8-linux-x86_64.egg/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/py_3.8/lib/python3.8/site-packages/torchvision-0.15.0a0+c206a47-py3.8-linux-x86_64.egg/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = XunFeiNet()\n",
    "model = model.to(device)\n",
    "lr = 0.009\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2faad78-e794-4f31-8b56-1a64dbf89ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 3.388678789138794\n",
      "Train loss 1.9799878597259521\n",
      "Train loss 1.452166199684143\n",
      "Train loss 0.9562422633171082\n",
      "Train loss 0.9234104156494141\n",
      "Train loss 0.8577191829681396\n",
      "1.4012843057622804 0.7952369260986988\n",
      "Train loss 0.7218042016029358\n",
      "Train loss 0.5972363352775574\n",
      "Train loss 0.954531729221344\n",
      "Train loss 0.9149355292320251\n",
      "Train loss 0.7557108402252197\n",
      "Train loss 0.8184840679168701\n",
      "0.6931042657507693 0.8347655290940339\n",
      "Train loss 0.6208568215370178\n",
      "Train loss 0.7852361798286438\n",
      "Train loss 0.7617814540863037\n",
      "Train loss 0.8572635054588318\n",
      "Train loss 0.7386090755462646\n",
      "Train loss 0.5402775406837463\n",
      "0.5930682874339468 0.8502332433095998\n",
      "Train loss 0.546901524066925\n",
      "Train loss 0.3939149081707001\n",
      "Train loss 0.26353999972343445\n",
      "Train loss 0.4136384427547455\n",
      "Train loss 0.7504159808158875\n",
      "Train loss 0.8162568807601929\n",
      "0.5448748861740836 0.8634912840657991\n",
      "Train loss 0.4091905951499939\n",
      "Train loss 0.26601487398147583\n",
      "Train loss 0.4526286721229553\n",
      "Train loss 0.53131103515625\n",
      "Train loss 0.7115647792816162\n",
      "Train loss 0.49206340312957764\n",
      "0.50118892983643 0.8070218512153204\n",
      "Train loss 0.7065068483352661\n",
      "Train loss 0.7007114887237549\n",
      "Train loss 0.43372631072998047\n",
      "Train loss 0.324689120054245\n",
      "Train loss 0.618479311466217\n",
      "Train loss 0.39967742562294006\n",
      "0.47555480583790033 0.8747851706358949\n",
      "Train loss 0.21853819489479065\n",
      "Train loss 0.5945806503295898\n",
      "Train loss 0.6278523802757263\n",
      "Train loss 0.8222844004631042\n",
      "Train loss 0.43751397728919983\n",
      "Train loss 0.28753259778022766\n",
      "0.4541537467362907 0.8738030935428431\n",
      "Train loss 0.41980651021003723\n",
      "Train loss 0.5659175515174866\n",
      "Train loss 0.5156697034835815\n",
      "Train loss 0.5123200416564941\n",
      "Train loss 0.7410581707954407\n",
      "Train loss 0.31091275811195374\n",
      "0.44055708017035883 0.8701203044438989\n",
      "Train loss 0.2671591341495514\n",
      "Train loss 0.38488414883613586\n",
      "Train loss 0.4370526969432831\n",
      "Train loss 0.5190554857254028\n",
      "Train loss 0.21725021302700043\n",
      "Train loss 0.7383965253829956\n",
      "0.4174264833495459 0.8738030935428431\n",
      "Train loss 0.40806373953819275\n",
      "Train loss 0.42056575417518616\n",
      "Train loss 0.5922966003417969\n",
      "Train loss 0.26931238174438477\n",
      "Train loss 0.3069310784339905\n",
      "Train loss 0.22887377440929413\n",
      "0.4203104139305651 0.8575988215074883\n",
      "Train loss 0.454436719417572\n",
      "Train loss 0.36956894397735596\n",
      "Train loss 0.5834987759590149\n",
      "Train loss 0.27965450286865234\n",
      "Train loss 0.385775625705719\n",
      "Train loss 0.5316051244735718\n",
      "0.4042744646944544 0.8720844586300025\n",
      "Train loss 0.22733452916145325\n",
      "Train loss 0.5767706632614136\n",
      "Train loss 0.2841898500919342\n",
      "Train loss 0.3667990565299988\n",
      "Train loss 0.3344745635986328\n",
      "Train loss 0.41879263520240784\n",
      "0.39208758514210146 0.8617726491529585\n",
      "Train loss 0.3439812660217285\n",
      "Train loss 0.4212128221988678\n",
      "Train loss 0.7333914637565613\n",
      "Train loss 0.6166045069694519\n",
      "Train loss 0.34113970398902893\n",
      "Train loss 0.2566286027431488\n",
      "0.3952107197837904 0.8816597102872575\n",
      "Train loss 0.2271513193845749\n",
      "Train loss 0.6135482788085938\n",
      "Train loss 0.3135901093482971\n",
      "Train loss 0.5260123014450073\n",
      "Train loss 0.4496265947818756\n",
      "Train loss 0.36556941270828247\n",
      "0.37948863784892156 0.86938374662411\n",
      "Train loss 0.4068053960800171\n",
      "Train loss 0.253447949886322\n",
      "Train loss 0.7561542391777039\n",
      "Train loss 0.12309996783733368\n",
      "Train loss 0.274734765291214\n",
      "Train loss 0.03981368616223335\n",
      "0.36774854717762484 0.8811686717407317\n",
      "Train loss 0.33761703968048096\n",
      "Train loss 0.3639411926269531\n",
      "Train loss 0.5423566699028015\n",
      "Train loss 0.5906764268875122\n",
      "Train loss 0.06833453476428986\n",
      "Train loss 0.05055611580610275\n",
      "0.3594203107059002 0.8615271298796956\n",
      "Train loss 0.45166486501693726\n",
      "Train loss 0.44106051325798035\n",
      "Train loss 0.13558319211006165\n",
      "Train loss 0.28560420870780945\n",
      "Train loss 0.26329270005226135\n",
      "Train loss 0.5367149710655212\n",
      "0.35657545371556326 0.8728210164497913\n",
      "Train loss 0.2147541642189026\n",
      "Train loss 0.12966389954090118\n",
      "Train loss 0.7318429350852966\n",
      "Train loss 0.40753740072250366\n",
      "Train loss 0.283711314201355\n",
      "Train loss 0.5403833985328674\n",
      "0.34084144380861237 0.8833783452000982\n",
      "Train loss 0.24663227796554565\n",
      "Train loss 0.28556886315345764\n",
      "Train loss 0.3841080665588379\n",
      "Train loss 0.26732251048088074\n",
      "Train loss 0.533252477645874\n",
      "Train loss 0.40795785188674927\n",
      "0.34251575545503704 0.8760127670022096\n",
      "Train loss 0.5090079307556152\n",
      "Train loss 0.21368524432182312\n",
      "Train loss 0.32196977734565735\n",
      "Train loss 0.6189671158790588\n",
      "Train loss 0.30058982968330383\n",
      "Train loss 0.29799404740333557\n",
      "0.3298383457586169 0.8954087895899828\n",
      "Train loss 0.3091262876987457\n",
      "Train loss 0.23823577165603638\n",
      "Train loss 0.535099983215332\n",
      "Train loss 0.22958996891975403\n",
      "Train loss 0.5328394174575806\n",
      "Train loss 0.43706974387168884\n",
      "0.34126353915438384 0.8502332433095998\n",
      "Train loss 0.460825651884079\n",
      "Train loss 0.4396797716617584\n",
      "Train loss 0.2531037926673889\n",
      "Train loss 0.2504483461380005\n",
      "Train loss 0.24311496317386627\n",
      "Train loss 0.34360602498054504\n",
      "0.3349623103516505 0.8784679597348392\n",
      "Train loss 0.2652346193790436\n",
      "Train loss 0.30176642537117004\n",
      "Train loss 0.4007973074913025\n",
      "Train loss 0.2202136516571045\n",
      "Train loss 0.18940454721450806\n",
      "Train loss 0.4710169732570648\n",
      "0.32275678637875793 0.8708568622636877\n",
      "Train loss 0.5897244811058044\n",
      "Train loss 0.13300856947898865\n",
      "Train loss 0.434817910194397\n",
      "Train loss 0.30949732661247253\n",
      "Train loss 0.4660549461841583\n",
      "Train loss 0.5850240588188171\n",
      "0.3264833439675653 0.8811686717407317\n",
      "Train loss 0.33165401220321655\n",
      "Train loss 0.17561133205890656\n",
      "Train loss 0.3013474643230438\n",
      "Train loss 0.5589924454689026\n",
      "Train loss 0.3424811363220215\n",
      "Train loss 0.41330721974372864\n",
      "0.3285723480820546 0.8919715197643014\n",
      "Train loss 0.21238936483860016\n",
      "Train loss 0.12373827397823334\n",
      "Train loss 0.09748230129480362\n",
      "Train loss 0.1539209485054016\n",
      "Train loss 0.5507338047027588\n",
      "Train loss 0.45844125747680664\n",
      "0.319275246868047 0.8804321139209428\n",
      "Train loss 0.44883209466934204\n",
      "Train loss 0.3014186918735504\n",
      "Train loss 0.22576047480106354\n",
      "Train loss 0.3884458541870117\n",
      "Train loss 0.44059720635414124\n",
      "Train loss 0.1752062439918518\n",
      "0.3035995269790018 0.8865700957525166\n",
      "Train loss 0.3444768786430359\n",
      "Train loss 0.26780936121940613\n",
      "Train loss 0.23259954154491425\n",
      "Train loss 0.34639623761177063\n",
      "Train loss 0.54312664270401\n",
      "Train loss 0.31731414794921875\n",
      "0.3127647897516213 0.8679106309845322\n",
      "Train loss 0.2728239595890045\n",
      "Train loss 0.2167002409696579\n",
      "Train loss 0.4947443902492523\n",
      "Train loss 0.13815619051456451\n",
      "Train loss 0.11773285269737244\n",
      "Train loss 0.3002413213253021\n",
      "0.3011984458357534 0.8863245764792537\n",
      "Train loss 0.12407159060239792\n",
      "Train loss 0.3921196758747101\n",
      "Train loss 0.19458508491516113\n",
      "Train loss 0.5588967204093933\n",
      "Train loss 0.2710169851779938\n",
      "Train loss 0.23467616736888885\n",
      "0.29091060958864334 0.8897618463049349\n",
      "Train loss 0.6450915932655334\n",
      "Train loss 0.3735671937465668\n",
      "Train loss 0.26170477271080017\n",
      "Train loss 0.37747132778167725\n",
      "Train loss 0.24278762936592102\n",
      "Train loss 0.21345853805541992\n",
      "0.3055030049804105 0.8917260004910386\n",
      "Train loss 0.1481652855873108\n",
      "Train loss 0.6331003308296204\n",
      "Train loss 0.24908752739429474\n",
      "Train loss 0.32219797372817993\n",
      "Train loss 0.14653722941875458\n",
      "Train loss 0.03390855714678764\n",
      "0.2976104570295908 0.8927080775840903\n",
      "Train loss 0.018321318551898003\n",
      "Train loss 0.4898175895214081\n",
      "Train loss 0.07714901119470596\n",
      "Train loss 0.349231094121933\n",
      "Train loss 0.05177170783281326\n",
      "Train loss 0.08415456116199493\n",
      "0.30673881977632206 0.8963908666830346\n",
      "Train loss 0.4680100977420807\n",
      "Train loss 0.40217745304107666\n",
      "Train loss 0.3394107520580292\n",
      "Train loss 0.15783093869686127\n",
      "Train loss 0.4533610939979553\n",
      "Train loss 0.7704455852508545\n",
      "0.30170094778740725 0.8904984041247238\n",
      "Train loss 0.43287408351898193\n",
      "Train loss 0.055779196321964264\n",
      "Train loss 0.2675781846046448\n",
      "Train loss 0.27914249897003174\n",
      "Train loss 0.32982826232910156\n",
      "Train loss 0.3661593794822693\n",
      "0.28735774580747925 0.8904984041247238\n",
      "Train loss 0.19316595792770386\n",
      "Train loss 0.3751966655254364\n",
      "Train loss 0.41696521639823914\n",
      "Train loss 0.6896100640296936\n",
      "Train loss 0.16861025989055634\n",
      "Train loss 0.19205790758132935\n",
      "0.29978272147127427 0.8850969801129389\n",
      "Train loss 0.30350303649902344\n",
      "Train loss 0.3009844124317169\n",
      "Train loss 0.3836084306240082\n",
      "Train loss 0.27387797832489014\n",
      "Train loss 0.1591661423444748\n",
      "Train loss 0.12911567091941833\n",
      "0.29108258573721874 0.899828136508716\n",
      "Train loss 0.3005463480949402\n",
      "Train loss 0.35144999623298645\n",
      "Train loss 0.1968510001897812\n",
      "Train loss 0.18152570724487305\n",
      "Train loss 0.37248486280441284\n",
      "Train loss 0.426411509513855\n",
      "0.28231744899976013 0.834028971274245\n",
      "Train loss 0.3826587498188019\n",
      "Train loss 0.13415472209453583\n",
      "Train loss 0.11096008867025375\n",
      "Train loss 0.31851673126220703\n",
      "Train loss 0.30995437502861023\n",
      "Train loss 0.26024502515792847\n",
      "0.2860605410533026 0.8875521728455684\n",
      "Train loss 0.4026200473308563\n",
      "Train loss 0.7237634062767029\n",
      "Train loss 0.4789852797985077\n",
      "Train loss 0.20533373951911926\n",
      "Train loss 0.09483454376459122\n",
      "Train loss 0.2654433846473694\n",
      "0.2817909733934999 0.8880432113920943\n",
      "train done\n"
     ]
    }
   ],
   "source": [
    "for _  in range(40):\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_acc  = validate(val_loader, model, criterion)\n",
    "    print(train_loss, val_acc)\n",
    "print(\"train done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c342ae2-1004-41af-bbe5-0b76f4d46a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "torch.save(model.state_dict(), 'model_820.pt')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9b8c959-cc6c-4389-9f97-1fcced231644",
   "metadata": {},
   "source": [
    "文件夹可以组织为如下格式：\n",
    "leafs-test/\n",
    "leafs-test/model/\n",
    "leafs-test/model/model.pt\n",
    "leafs-test/.ipynb_checkpoints/\n",
    "leafs-test/.ipynb_checkpoints/run-checkpoint.py\n",
    "leafs-test/run.py\n",
    "\n",
    "tar -cvzf leafs-test.tar.gz leafs-test/\n",
    "s3cmd put leafs-test.tar.gz s3://ai-competition/你的URL/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aab234-cff6-4866-99c7-ef4e13080700",
   "metadata": {},
   "source": [
    "run.py 内容如下：\n",
    "\n",
    "```python\n",
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = 0\n",
    "        \n",
    "        return img, torch.from_numpy(np.array(label).astype(int))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "class XunFeiNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet, self).__init__()\n",
    "        model = models.resnet50(False)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(2048, 25)\n",
    "        self.resnet = model\n",
    "    \n",
    "    def forward(self, img):\n",
    "        out = self.resnet(img)\n",
    "        return out\n",
    "    \n",
    "def predict(test_loader, model):\n",
    "    model.eval()    \n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)\n",
    "            test_pred.append(output.data.cpu().numpy())\n",
    "            \n",
    "    return np.vstack(test_pred)\n",
    "\n",
    "\n",
    "test_path = glob.glob('/work/data/birds-test-dataset/*')\n",
    "test_path.sort()\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(test_path[:],\n",
    "    transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                # transforms.RandomResizedCrop(224),\n",
    "                # transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ])), batch_size=30, shuffle=False, num_workers=1, pin_memory=False\n",
    ")\n",
    "model = XunFeiNet()\n",
    "model.load_state_dict(torch.load('./model/model.pt'))\n",
    "\n",
    "test_pred = predict(test_loader, model)\n",
    "test_pred = test_pred.argmax(1)\n",
    "# class_names = np.array(['Asian Green Bee-Eater', 'Brown-Headed Barbet', 'Cattle Egret',\n",
    "#        'Common Kingfisher', 'Common Myna', 'Common Rosefinch',\n",
    "#        'Common Tailorbird', 'Coppersmith Barbet', 'Forest Wagtail',\n",
    "#        'Gray Wagtail', 'Hoopoe', 'House Crow', 'Indian Grey Hornbill',\n",
    "#        'Indian Peacock', 'Indian Pitta', 'Indian Roller',\n",
    "#        'Jungle Babbler', 'Northern Lapwing', 'Red-Wattled Lapwing',\n",
    "#        'Ruddy Shelduck', 'Rufous Treepie', 'Sarus Crane', 'White Wagtail',\n",
    "#        'White-Breasted Kingfisher', 'White-Breasted Waterhen'])\n",
    "# test_pred = class_names[test_pred]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'imageID': [x.split('/')[-1] for x in test_path],\n",
    "    'label': test_pred\n",
    "}).to_csv('/work/output/result.csv', index=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00dec7-f842-459a-b2c6-e108dc9b522b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b893d0-d22e-401a-b39a-4810c7ec7e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
